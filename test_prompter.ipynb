{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort this list using merge sort algorithm [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "from graph_of_thoughts.prompter import LanguageModelPrompter\n",
    "from graph_of_thoughts.language_model import ChatGPT\n",
    "lm = ChatGPT()\n",
    "prompter = LanguageModelPrompter(lm, \"Sort this list using merge sort algorithm\")\n",
    "list = \"[9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\"\n",
    "num_split = 4\n",
    "print(f\"Sort this list using merge sort algorithm {list}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Instruction>Please split the list into four equal parts. \n",
      "Only output the 4 results in format json {\"0\":..., \"1\": ...} without any addtional text or thoughts.</Instruction>\n",
      "Input: [9, 6, 7, 7, 2, 0, 2, 2, 3, 5, 0, 9, 2, 2, 4, 4, 5, 2, 5, 1, 2, 8, 3, 8, 3, 9, 6, 0, 4, 2, 2, 3]\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "split_prompt_raw = prompter.split_prompt({\"state\": f\"Sort this list using merge sort algorithm\\nInput\", \"num_split\": num_split})\n",
    "split_prompt = f\"<Instruction>{split_prompt_raw} \\nOnly output the {num_split} results in format json {{\\\"0\\\":..., \\\"1\\\": ...}} without any addtional text or thoughts.</Instruction>\\nInput: {list}\\nOutput:\"\n",
    "\n",
    "print(split_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"0\": [9, 6, 7, 7, 2, 0, 2, 2], \"1\": [3, 5, 0, 9, 2, 2, 4, 4], \"2\": [5, 2, 5, 1, 2, 8, 3, 8], \"3\": [3, 9, 6, 0, 4, 2, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "split_result = lm.get_response_texts(lm.query(split_prompt))[0]\n",
    "print(split_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "split_result_dict = json.loads(split_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_prompt_raw = prompter.generate_prompt({\"state\": split_prompt_raw})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort the given list using the merge sort algorithm.\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 2, 6, 7, 7, 9]\n",
      "[0, 2, 2, 3, 4, 4, 5, 9]\n",
      "[1, 2, 2, 3, 5, 5, 8, 8]\n",
      "[0, 2, 2, 3, 3, 4, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "generate_result_dict = {}\n",
    "for k, v in split_result_dict.items():\n",
    "    generate_prompt = f\"\"\"<Instruction>{generate_prompt_raw} \\nOnly output the result in format json {{\\\"0\\\":}} without any addtional text or thoughts.</Instruction>\\nInput: {v}\\nOutput:\"\"\"\n",
    "    generate_result_dict[k] = json.loads(lm.get_response_texts(lm.query(generate_prompt))[0])[\"0\"]\n",
    "\n",
    "    print(generate_result_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': [0, 2, 2, 2, 6, 7, 7, 9], '1': [0, 2, 2, 3, 4, 4, 5, 9], '2': [1, 2, 2, 3, 5, 5, 8, 8], '3': [0, 2, 2, 3, 3, 4, 6, 9]}\n"
     ]
    }
   ],
   "source": [
    "print(generate_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sort the given list using the merge sort algorithm.\n"
     ]
    }
   ],
   "source": [
    "aggregate_prompt_raw = prompter.aggregate_prompt({\"state\": generate_prompt_raw})\n",
    "print(aggregate_prompt_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Instruction>Sort the given list using the merge sort algorithm. \n",
      "Only output the result in format json {\"0\":} without any addtional text or thoughts.</Instruction>\n",
      "Input: {'0': [0, 2, 2, 2, 6, 7, 7, 9], '1': [0, 2, 2, 3, 4, 4, 5, 9], '2': [1, 2, 2, 3, 5, 5, 8, 8], '3': [0, 2, 2, 3, 3, 4, 6, 9]}\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "aggregate_prompt = f\"<Instruction>{aggregate_prompt_raw} \\nOnly output the result in format json {{\\\"0\\\":}} without any addtional text or thoughts.</Instruction>\\nInput: {generate_result_dict}\\nOutput:\"\n",
    "print(aggregate_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\": [0, 0, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9]}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.get_response_texts(lm.query(aggregate_prompt))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_of_thought",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
